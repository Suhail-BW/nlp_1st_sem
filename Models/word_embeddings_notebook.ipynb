{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8760e455",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "from enum import Enum\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim.downloader\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import torch\n",
    "import torch.nn.functional as functional\n",
    "import sklearn.metrics as sk_metrics\n",
    "from wordcloud import WordCloud\n",
    "from scipy.spatial import distance\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from transformers import RobertaModel, RobertaTokenizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d95627",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b05e1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../Data/Restaurant reviews.csv\"\n",
    "df = pd.read_csv(data_path, dtype=str, na_filter=False)\n",
    "\n",
    "for rating in range(1, 6):\n",
    "    df_score_k = df[df[\"Rating\"] == str(rating)]\n",
    "    print(rating, df_score_k.size)\n",
    "    # df_score_k.to_csv(f\"../Data/reviews_rating_{rating}.csv\")\n",
    "\n",
    "restaurant_names = df[\"Restaurant\"].tolist()\n",
    "restaurant_names = set(restaurant_names)\n",
    "for restaurant_name in restaurant_names:\n",
    "    df_by_name = df[df[\"Restaurant\"] == restaurant_name]\n",
    "    # print(restaurant_name, df_by_name.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c403b714",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, valid_df, test_df = None, None, None\n",
    "# df[\"Rating\"] = df[\"Rating\"].replace(\"1.5\", \"2\")\n",
    "# df[\"Rating\"] = df[\"Rating\"].replace(\"2.5\", \"3\")\n",
    "# df[\"Rating\"] = df[\"Rating\"].replace(\"3.5\", \"4\")\n",
    "# df[\"Rating\"] = df[\"Rating\"].replace(\"4.5\", \"5\")\n",
    "print(df[\"Rating\"].unique(), len(df))\n",
    "\n",
    "for rating in range(1, 6):\n",
    "    df_score_k = df[df[\"Rating\"] == str(rating)]\n",
    "    step_train_df, step_test_df = train_test_split(df_score_k, test_size=0.2)\n",
    "    step_train_df, step_valid_df = train_test_split(step_train_df, test_size=0.2)\n",
    "\n",
    "    if train_df is None:\n",
    "        train_df = step_train_df\n",
    "        valid_df = step_valid_df\n",
    "        test_df = step_test_df\n",
    "    else:\n",
    "        train_df = pd.concat([train_df, step_train_df], axis=0)\n",
    "        valid_df = pd.concat([valid_df, step_valid_df], axis=0)\n",
    "        test_df = pd.concat([test_df, step_test_df], axis=0)\n",
    "\n",
    "    # step_train_df.to_csv(f\"../Data/review_train_data_{rating}.csv\", index=False)\n",
    "    print(len(step_train_df), len(df_score_k))\n",
    "\n",
    "train_df.reset_index(drop=True)\n",
    "valid_df.reset_index(drop=True)\n",
    "test_df.reset_index(drop=True)\n",
    "# train_df.to_csv(f\"../Data/review_train_data.csv\", index=False)\n",
    "# valid_df.to_csv(f\"../Data/review_valid_data.csv\", index=False)\n",
    "# test_df.to_csv(f\"../Data/review_test_data.csv\", index=False)\n",
    "print(len(train_df), len(valid_df), len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a20fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_reviews_of_rating(rating):\n",
    "    csv_path = f\"../Data/reviews_rating_{rating}.csv\"\n",
    "    df = pd.read_csv(csv_path, dtype=str, na_filter=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "def filter_reviews_by_restaurant_name(df, restaurant_name):\n",
    "    if restaurant_name is None:\n",
    "        return df\n",
    "    return df[df[\"Restaurant\"] == restaurant_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7d89ff",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5051563e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_generator = WordCloud(\n",
    "    max_words=200,\n",
    "    stopwords=None,\n",
    "    collocations=False,\n",
    "    normalize_plurals=True,\n",
    ")\n",
    "\n",
    "for rating in range(1, 6):\n",
    "    df = read_reviews_of_rating(rating)\n",
    "\n",
    "    reviews = df[\"Review\"]\n",
    "    cloud = cloud_generator.generate(\"\\n\".join([str(review) for review in reviews]))\n",
    "\n",
    "    plt.imshow(cloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6f7036",
   "metadata": {},
   "source": [
    "## Task 4+5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b50e836",
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim_word_embeddings = {\n",
    "    \"fasttext\": gensim.downloader.load(\"fasttext-wiki-news-subwords-300\"),\n",
    "    \"glove\": gensim.downloader.load(\"glove-wiki-gigaword-300\"),\n",
    "    \"word2vec\": gensim.downloader.load(\"word2vec-google-news-300\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90be0eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To change which BERT embeddings to use, or RoBERTa, change it here\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "# bert_model = BertModel.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "# bert_tokenizer = BertTokenizer.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "# bert_model = RobertaModel.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "# bert_tokenizer = RobertaTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment-latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d250fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "EmbeddingName = Enum(\"Embedding_Name\", [\"fasttext\", \"glove\", \"word2vec\", \"bert\"])\n",
    "\n",
    "\n",
    "class WordEmbeddings:\n",
    "    def __init__(self, model_name: EmbeddingName):\n",
    "        self.gensim_word_embeddings = gensim_word_embeddings\n",
    "        self.bert_model = bert_model\n",
    "        self.bert_tokenizer = bert_tokenizer\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.model_name = model_name\n",
    "\n",
    "        self.bert_model = self.bert_model.to(self.device)\n",
    "        self.bert_model.eval()\n",
    "\n",
    "    def get_word_embedding(self, word: str):\n",
    "        if self.model_name == EmbeddingName.bert:\n",
    "            return self.get_sentence_embedding(word)\n",
    "        return self.gensim_word_embeddings[self.model_name.name].get_vector(word)\n",
    "\n",
    "    def check_word_exists(self, word: str):\n",
    "        if self.model_name == EmbeddingName.bert:\n",
    "            return True\n",
    "        return self.gensim_word_embeddings[self.model_name.name].has_index_for(word)\n",
    "\n",
    "    def get_sentence_embedding(self, sentence: str):\n",
    "        if self.model_name == EmbeddingName.bert:\n",
    "            tokens = self.bert_tokenizer.encode(\n",
    "                sentence,\n",
    "                max_length=512,\n",
    "                truncation=True,\n",
    "                add_special_tokens=False)\n",
    "            bert_inputs = torch.tensor([\n",
    "                self.bert_tokenizer.build_inputs_with_special_tokens(tokens),\n",
    "            ]).to(self.device)\n",
    "            with torch.no_grad():\n",
    "                pooler_output = self.bert_model(bert_inputs)[0][:, 0]\n",
    "            sentence_embedding = pooler_output.squeeze().detach().cpu().numpy()\n",
    "\n",
    "        else:\n",
    "            tokens = nltk.word_tokenize(sentence)\n",
    "            embeddings = [\n",
    "                self.get_word_embedding(token)\n",
    "                for token in tokens\n",
    "                if self.check_word_exists(token)\n",
    "            ]\n",
    "            if len(embeddings) == 0:\n",
    "                raise ValueError(f\"Invalid sentence: '{sentence}'!\")\n",
    "            sentence_embedding = np.mean(embeddings, axis=0)\n",
    "\n",
    "        return sentence_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e724b68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_generator = WordEmbeddings(EmbeddingName.bert)\n",
    "restaurant_name = None\n",
    "\n",
    "reviews_of_rating_1 = filter_reviews_by_restaurant_name(\n",
    "    read_reviews_of_rating(1),\n",
    "    restaurant_name=restaurant_name,\n",
    ")[\"Review\"]\n",
    "reviews_of_rating_2 = filter_reviews_by_restaurant_name(\n",
    "    read_reviews_of_rating(2),\n",
    "    restaurant_name=restaurant_name,\n",
    ")[\"Review\"]\n",
    "reviews_of_rating_3 = filter_reviews_by_restaurant_name(\n",
    "    read_reviews_of_rating(3),\n",
    "    restaurant_name=restaurant_name,\n",
    ")[\"Review\"]\n",
    "reviews_of_rating_4 = filter_reviews_by_restaurant_name(\n",
    "    read_reviews_of_rating(4),\n",
    "    restaurant_name=restaurant_name,\n",
    ")[\"Review\"]\n",
    "reviews_of_rating_5 = filter_reviews_by_restaurant_name(\n",
    "    read_reviews_of_rating(5),\n",
    "    restaurant_name=restaurant_name,\n",
    ")[\"Review\"]\n",
    "\n",
    "print(len(reviews_of_rating_1), len(reviews_of_rating_2), len(reviews_of_rating_4), len(reviews_of_rating_5))\n",
    "num_samples = 200\n",
    "\n",
    "for embedding_name in EmbeddingName:\n",
    "    i = 0\n",
    "    true_count = 0\n",
    "    embedding_generator.model_name = embedding_name\n",
    "\n",
    "    while i < num_samples:\n",
    "        random_review_rating_1 = reviews_of_rating_1.sample(1).squeeze()\n",
    "        random_review_rating_2 = reviews_of_rating_2.sample(1).squeeze()\n",
    "        random_review_rating_4 = reviews_of_rating_4.sample(1).squeeze()\n",
    "\n",
    "        try:\n",
    "            embedding_review_rating_1 = embedding_generator.get_sentence_embedding(random_review_rating_1)\n",
    "            embedding_review_rating_2 = embedding_generator.get_sentence_embedding(random_review_rating_2)\n",
    "            embedding_review_rating_4 = embedding_generator.get_sentence_embedding(random_review_rating_4)\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "        same_sentiment_distance = distance.cosine(embedding_review_rating_1, embedding_review_rating_2)\n",
    "        diff_sentiment_distance = distance.cosine(embedding_review_rating_1, embedding_review_rating_4)\n",
    "        if same_sentiment_distance < diff_sentiment_distance:\n",
    "            true_count += 1\n",
    "        # print(f\"same_sentiment ({same_sentiment_distance}) < diff_sentiment ({diff_sentiment_distance})\")\n",
    "        i += 1\n",
    "\n",
    "    print(embedding_name, true_count / num_samples)\n",
    "# fasttext 0.49, glove 0.494, word2vec 0.532, bert 0.525, bert 0.926, roberta 0.936"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0681af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_generator = WordEmbeddings(EmbeddingName.bert)\n",
    "\n",
    "\n",
    "def get_embedding_of_dataframe(reviews):\n",
    "    num_reviews = len(reviews)\n",
    "    df_embedding = None\n",
    "\n",
    "    for review in reviews:\n",
    "        try:\n",
    "            embedding = embedding_generator.get_sentence_embedding(review)\n",
    "        except ValueError as e:\n",
    "            print(review)\n",
    "            raise e\n",
    "        if df_embedding is None:\n",
    "            df_embedding = embedding / num_reviews\n",
    "        else:\n",
    "            df_embedding += embedding / num_reviews\n",
    "    return df_embedding\n",
    "\n",
    "\n",
    "embedding_by_rating = {\n",
    "    score: get_embedding_of_dataframe(read_reviews_of_rating(score)[\"Review\"])\n",
    "    for score in range(1, 6)\n",
    "}\n",
    "distance_matrix = torch.zeros(5, 5)\n",
    "for i in range(1, 6):\n",
    "    for j in range(1, 6):\n",
    "        distance_matrix[i - 1, j - 1] = distance.cosine(\n",
    "            embedding_by_rating[i],\n",
    "            embedding_by_rating[j],\n",
    "        )\n",
    "for i in range(5):\n",
    "    print(distance_matrix[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de75c2da",
   "metadata": {},
   "source": [
    "## Task 9: Model Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c71b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(f\"../Data/review_test_data.csv\")\n",
    "targets = test_df[\"Rating\"].astype(int).values\n",
    "\n",
    "method_names = [\n",
    "    \"vicuna\",\n",
    "    # \"bert_fc-False_pooler-False_transformer-False_d0.2_wd1e-4_lr1e-4\",\n",
    "    # \"bert_fc-False_pooler-False_transformer-True_d0.0_wd1e-5_lr1e-4\",\n",
    "    # \"bert_fc-True_pooler-False_transformer-False_d0.0_wd1e-4_lr1e-3\",\n",
    "    # \"bert_fc-True_pooler-True_transformer-False_d0.0_wd1e-5_lr1e-4\",\n",
    "    # \"roberta_fc-False_pooler-False_transformer-False_d0.2_wd1e-5_lr1e-4\",\n",
    "    # \"roberta_fc-True_pooler-False_transformer-False_d0.0_wd1e-4_lr1e-4\",\n",
    "    # \"roberta_fc-True_pooler-True_transformer-False_d0.0_wd1e-5_lr1e-4\",\n",
    "    \"roberta_fc-False_pooler-False_transformer-True_d0.0_wd1e-4_lr1e-4\",\n",
    "]\n",
    "\n",
    "for method_name in method_names:\n",
    "    if method_name == \"vicuna\":\n",
    "        output_path = os.path.join(\"../../weights/results.json\")\n",
    "    else:\n",
    "        output_path = os.path.join(\"../../weights\", method_name, \"outputs.npy\")\n",
    "\n",
    "    if output_path.endswith(\".npy\"):\n",
    "        outputs = np.load(output_path)\n",
    "    elif output_path.endswith(\".json\"):\n",
    "        outputs = json.load(open(output_path))\n",
    "        # If the output is ill-defined, use the neutral rating\n",
    "        outputs = np.array([\n",
    "            (out[\"rating\"] if out[\"rating\"] in range(1, 6) else 3)\n",
    "            for out in outputs\n",
    "        ])\n",
    "\n",
    "    accuracy = sk_metrics.accuracy_score(targets, outputs)\n",
    "    f1_score = sk_metrics.f1_score(targets, outputs, average=\"weighted\")\n",
    "    precision = sk_metrics.precision_score(targets, outputs, average=\"weighted\")\n",
    "    recall = sk_metrics.recall_score(targets, outputs, average=\"weighted\")\n",
    "    print(f\"{method_name}: {accuracy:.5f} {f1_score:.5f} {precision:.5f} {recall:.5f}\")\n",
    "\n",
    "    if method_name != \"roberta_fc-False_pooler-False_transformer-True_d0.0_wd1e-4_lr1e-4\":\n",
    "        continue\n",
    "\n",
    "    confusion_matrix = sk_metrics.ConfusionMatrixDisplay.from_predictions(targets, outputs)\n",
    "    # confusion_matrix.plot()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d20e337",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
